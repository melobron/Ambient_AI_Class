{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2WB3osOu1k6"
      },
      "source": [
        "# | Practice 3-2 | Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX-KR0Ehu1k8"
      },
      "source": [
        "**Pre-trained Model**은 ImageNet과 같은 대규모(Large-scale) 데이터셋에서 학습 후 저장된 네트워크로, 일반적으로 대규모 Image classification task에서 학습된 것이다. <br>\n",
        "학습된 모델은 그대로 사용하거나, **Transfer Learning**을 이용하여 새로운 task에 사용할 수 있다. <br>\n",
        "\n",
        "이번 실습에서는 ***MobileNetV2*** 구조로 **ImageNet 데이터셋에 학습한 Pre-trained Model을 활용**하여 **Transfer Learning으로 개와 고양이를 분류**하는 모델을 만든다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSh5rd2Mu1k8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8973gPHu1k8"
      },
      "source": [
        "## (Optional) Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqyc2VvOu1k9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xlUIaDpu1k9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Change directory to where this file is located\n",
        "\"\"\"\n",
        "%cd 'COPY&PASTE FILE DIRECTORY HERE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLSlgYXIu1k9"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCVR1Vgau1k-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV603ATou1k_"
      },
      "source": [
        "## GPU Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM1FtxLwu1k_"
      },
      "outputs": [],
      "source": [
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h--u-L4gu1k_"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Make sure your runtime type is GPU!\n",
        "\"\"\"\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print('Num_GPUs:{}, List:{}'.format(len(physical_devices), physical_devices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU9qk3ZMu1k_"
      },
      "outputs": [],
      "source": [
        "gpu_growth = False\n",
        "\n",
        "if gpu_growth:\n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    except:\n",
        "        # Invalid device or cannot modify virtual devices once initialized.\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rUJP203u1k_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkDCPJVNu1lA"
      },
      "source": [
        "## 0. Dataset : Cats and Dogs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Yy90P6u1lA"
      },
      "source": [
        "### (1) Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo9YIYM3KFvh"
      },
      "source": [
        "`tf.keras.utils.get_file` 을 이용하여 데이터를 다운로드한다. <br>\n",
        "- `fname`: 파일 이름. 절대경로가 지정되면 해당 위치에 파일이 저장됨\n",
        "- `origin`: 파일을 받아오는 경로\n",
        "- `extract`: True로 설정하면 tar 또는 zip과 같은 파일을 아카이브로 추출하려고 시도함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8HrQ-J4u1lA"
      },
      "outputs": [],
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file(fname='cats_and_dogs.zip', \n",
        "                                      origin=_URL, \n",
        "                                      extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "print(path_to_zip)\n",
        "print(PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhiz1ZTWKFvi"
      },
      "source": [
        "### (2) Create Train / Valid / Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvXr8fWAKFvi"
      },
      "source": [
        "**Train / Valid**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7xfOo_GKFvi"
      },
      "source": [
        "`tf.keras.preprocessing.image_dataset_from_directory`를 이용하여 training / validation 을 위한 `tf.data.Dataset`을 생성한다. <br>\n",
        "(디렉토리 내의 이미지 파일들로부터 `tf.data.Dataset`을 생성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK47waK0KFvi"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39JgXTVcKFvi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# train dataset\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)\n",
        "# valid dataset\n",
        "validation_dataset = image_dataset_from_directory(validation_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdPpVjwWKFvi"
      },
      "source": [
        "`as_numpy_iterator` 메소드는 Dataset의 모든 요소를 numpy로 변환하는 iterator를 리턴하는데, 이것을 리스트에 담아서 데이터셋을 출력해볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chsClW-aKFvi"
      },
      "outputs": [],
      "source": [
        "dataset_list = list(train_dataset.as_numpy_iterator())\n",
        "print(len(dataset_list))\n",
        "print(f\"images: {dataset_list[0][0].shape}\")\n",
        "print(f\"labels: {dataset_list[0][1].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG-NVmsBKFvj"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSD85rF5KFvj"
      },
      "source": [
        "원본 데이터셋에는 test 데이터셋이 포함되어있지 않으므로 **valid 데이터셋의 20%를 test 데이터셋**으로 만든다.<br>\n",
        "`tf.data.experimental.cardinality`는 데이터셋의 batch size를 반환하는데, 32배치의 데이터셋을 5등분하고 올림하여 6개의 배치를 test 데이터셋으로 만든다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ID5Kcn9KFvj"
      },
      "outputs": [],
      "source": [
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "test_dataset = validation_dataset.take(val_batches // 5)\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z78BFhKPKFvj"
      },
      "outputs": [],
      "source": [
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93J960Eeu1lB"
      },
      "source": [
        "### (3) Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAH8rJSZu1lB"
      },
      "outputs": [],
      "source": [
        "class_names = train_dataset.class_names # ['cats', 'dogs']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "for images, labels in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk8Tz8NhKFvj"
      },
      "outputs": [],
      "source": [
        "for images, labels in train_dataset.take(1):\n",
        "    print(len(labels))\n",
        "    print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X32O3pHDKFvj"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxHnwGTcKFvj"
      },
      "source": [
        "## 1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHX4W1VuKFvj"
      },
      "source": [
        "### (1) Prefetching (Configure the dataset for performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-YhaB6EKFvj"
      },
      "source": [
        "Prefetching은 데이터 전처리와 학습 과정을 오버랩한다. 즉, 데이터가 소비되는 시간과 데이터가 생성되는 시간 사이의 의존성을 줄인다. (데이터 요청 시간 전에 데이터셋에서 데이터를 가져와 메모리에 올려둠) <br>\n",
        "- 가져올 데이터 수는 한 training step에서 소비하는 배치의 수와 같거나 커야한다.\n",
        "- `AUTOTUNE`을 사용하면 데이터를 고정적인 크기로 미리 가져와 메모리에 올려놓는것이 아니라 자원 현황에 따라 적절히 동적으로 값을 조정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oXmNVhtKFvj"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-NLjDjiKFvj"
      },
      "source": [
        "### (2) Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27M_Y4deKFvj"
      },
      "source": [
        "데이터셋 크기가 작은경우 training 데이터셋에 Rotation, Flip등을 무작위로 적용하여 **샘플의 다양성**을 인위적으로 도입하면 과대적합(over fitting)을 줄일 수 있다. <br>\n",
        "`tf.keras.layers.experimental.preprocessing`을 이용한다. <br>\n",
        "\n",
        "***참고*** ) `model.fit` 을 호출할 때 학습중에만 data augmentation 레이어가 활성화되고, `model.evaulate`에서는 비활성화된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsjX7uNJKFvk"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "                    ####### 실습 #######\n",
        "\n",
        "                    ###################\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLcwEDMbKFvk"
      },
      "outputs": [],
      "source": [
        "for image, _ in train_dataset.take(1):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    first_image = image[0]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
        "        plt.imshow(augmented_image[0] / 255)\n",
        "        plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATlk2wJiKFvk"
      },
      "source": [
        "### (3) Rescaling Pixel Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6urWM5hKFvk"
      },
      "source": [
        "이번 실습에서는 Tensorflow에서 제공해주는 MobileNetV2 모델, `tf.keras.applications.MobileNetV2`을 이용하는데, **이 모델의 input은 [0, 255] 픽셀값이 아닌 [-1, 1] 값을 사용**한다. <br>\n",
        "\n",
        "`tf.keras.applications.mobilenet_v2.preprocess_input`을 이용하면 모델에 맞춰 쉽게 preprocessing할 수 있다. <br>\n",
        "\n",
        "또는 `tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)`을 이용하여 rescaling해도 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4RGvp3mKFvk"
      },
      "outputs": [],
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HY5tVw2lznBv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn2khrLiKFvk"
      },
      "source": [
        "## 2. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qzhOlHSKFvk"
      },
      "source": [
        "### (1) Base Model from the pre-trained convnets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-2OEd2RKFvk"
      },
      "source": [
        "ImageNet데이터로 학습된 MobileNetV2 모델을 생성한다.\n",
        "- `input_shape`은 (160, 160, 3)으로 한다.\n",
        "- `include_top=False`로 설정하면 이미지 **feature extractor**만 가져오고 **classifier**는 가져오지 않는다.\n",
        "- `weights=imagenet`으로 설정하여 **ImageNet pre-trained model**을 가져올 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8s7ONQ8KFvk"
      },
      "outputs": [],
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "####### 실습 #######\n",
        "\n",
        "###################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lX4XBEBKFvk"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ly8-B0MKFvk"
      },
      "source": [
        "**Base model**에 데이터를 넣어 forward propagation 시킨 후 결과의 shape을 보면 (32, 5, 5, 1280) 으로, 32배치 데이터에 대해서 1280필터가 출력한 5x5 ***feature map***이 나온다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNBnC2IhKFvk"
      },
      "outputs": [],
      "source": [
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sgQsmCwKFvk"
      },
      "source": [
        "### (2) Feature Extraction (Freeze the convolutional base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AzkzV-HKFvk"
      },
      "source": [
        "**Base Model**은 잘 학습된 것이므로 **freeze**하여 새로 학습할 때 weights가 업데이트되지 않도록 해준다. 즉, 사전 학습된 정보가 손상되지 않도록 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6blhMOYQKFvk"
      },
      "outputs": [],
      "source": [
        "####### 실습 #######\n",
        "\n",
        "###################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXLVb_soKFvk"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2ab_LVlKFvl"
      },
      "source": [
        "### (3) Custom Classifier (Classification Head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXpe6AZrKFvl"
      },
      "source": [
        "개 / 고양이 분류를 할 수 있는 **binary classifier**를 새롭게 추가한다.\n",
        "\n",
        "정답 레이블이 고양이(0) 또는 개(1) 이므로, 최종적으로 **'개인지 아닌지'**만 판단해도 된다. <br>\n",
        "따라서 최종적으로 **1개 노드의 class 출력 레이어**를 만들것이다. (positive는 1, negative는 0인 logit을 출력)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "futGMz32KFvl"
      },
      "outputs": [],
      "source": [
        "print(f\"feature_batch shape: {feature_batch.shape}\")\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(f\"feature_batch_average shape: {feature_batch_average.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuMFncZwKFvl"
      },
      "outputs": [],
      "source": [
        "prediction_layer = tf.keras.layers.Dense(1)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oipcFY_vKFvl"
      },
      "source": [
        "CNN model에는 `tf.keras.layers.BatchNormalization` (BN layer)가 포함되어있는데, base model을 불러올 때 `training = False`로 설정하여 BN layer를 inference mode로 유지해야한다. <br>\n",
        "\n",
        "BN layer에는 학습 중 업데이트되는 학습 불가능한(input의 mean, variance 추적하는) 2개의 weights가 있는데, inference mode에서 실행해야 mean, variance 통계가 업데이트되지 않는다. 그렇지 않으면 학습 불가능한 weights에 적용된 업데이트로 인해 모델이 학습한 내용이 갑작스럽게 파괴될 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeH_tfmSKFvl"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Build a model by chaining together the data augmentation, rescaling, base_model and feature extractor layers \n",
        "* Use the Keras Functional API\n",
        "'''\n",
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "####### 실습 #######\n",
        "x = data_augmentation(inputs)\n",
        "\n",
        "###################\n",
        "model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "iyGK81gCzokU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH-Ho8f7KFvl"
      },
      "source": [
        "## 3. Model Compile & Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st99bRo_KFvl"
      },
      "source": [
        "### (1) Model Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPKCQv_NKFvl"
      },
      "source": [
        "- learning rate: 0.0001\n",
        "- optimizer: RMSprop\n",
        "- loss: binary cross entropy\n",
        "- metrics: 'accuracy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3FGOK_AKFvl"
      },
      "outputs": [],
      "source": [
        "####### 실습 #######\n",
        "base_learning_rate = 0.0001\n",
        "model.compile(\n",
        "\n",
        "              )\n",
        "###################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XllhSGJ_KFvl"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4hfApc7KFvl"
      },
      "outputs": [],
      "source": [
        "len(model.trainable_variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64lv_B9cKFvl"
      },
      "outputs": [],
      "source": [
        "model.trainable_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79R-ybc3KFvm"
      },
      "source": [
        "### (2) Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae-zXEPtKFvm"
      },
      "source": [
        "**Evaluation before training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbW-DR4aKFvm"
      },
      "outputs": [],
      "source": [
        "initial_epochs = 10\n",
        "loss0, accuracy0 = model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0r1piBMKFvm"
      },
      "outputs": [],
      "source": [
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOekiWOSKFvm"
      },
      "source": [
        "**Training & Evaluation** <br>\n",
        "\n",
        "`model.fit`을 하면, base model부분은 고정되어있으므로 **Custom classifier** 부분만 학습된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzFg7v99KFvm"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-_XF8CyKFvm"
      },
      "source": [
        "**Learning Curves**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PjppeEfKFvm"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sVaThJoKFvm"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Zeq5rlsVzqCk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIDjq5_FKFvm"
      },
      "source": [
        "## 4. Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfPtaHYIKFvm"
      },
      "source": [
        "Pre-trained base model의 일부 freeze를 해제하고, 낮은 learning rate로 전체 모델을 재학습시키는 **Fine Tuning**을 할 수 있다. 이를 통해 feature map이 새로운 데이터셋에 맞춰 조정되어 모델의 성능이 향상될 수 있다. <br>\n",
        "\n",
        "***Note***: 최상위 classifier를 학습한 뒤 시도해야한다. 만약 Pre-trained base model에 무작위로 초기화(randomly initialized)된 classifier를 추가하고 freeze를 해제한 뒤 학습하면 gradient update가 너무 커지고, pre-train한 것의 의미가 사라진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06fHf-0HKFvm"
      },
      "source": [
        "### (1) Un-freeze the top layers of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t0z-D7cKFvm"
      },
      "source": [
        "소수의 Top layer를 fine tuning한다. 이를 위해 base model의 freeze를 해제하고 bottom-layer를 un-trainable로 설정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oldJiwwlKFvm"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz-USea7KFvm"
      },
      "outputs": [],
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "####### 실습 #######\n",
        "\n",
        "###################\n",
        "        \n",
        "print(\"Number of trainable layers in the base model: \", len(base_model.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPBOGTNFKFvm"
      },
      "source": [
        "### (2) Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fibzGf_KFvm"
      },
      "outputs": [],
      "source": [
        "####### 실습 #######\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=),\n",
        "              metrics=['accuracy'])\n",
        "###################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKuLVo8NKFvm"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mLupFF7KFvn"
      },
      "outputs": [],
      "source": [
        "len(model.trainable_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdLQaaxZKFvn"
      },
      "source": [
        "### (3) Continue training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGo1UR7yKFvn"
      },
      "outputs": [],
      "source": [
        "fine_tune_epochs = 10\n",
        "total_epochs =  initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_dataset,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpF7zmQtKFvn"
      },
      "outputs": [],
      "source": [
        "acc += history_fine.history['accuracy']\n",
        "val_acc += history_fine.history['val_accuracy']\n",
        "\n",
        "loss += history_fine.history['loss']\n",
        "val_loss += history_fine.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXfnvKM3KFvn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.ylim([0.8, 1])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.ylim([0, 1.0])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSndxxsNKFvn"
      },
      "source": [
        "### (4) Evaluation and prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxM_4VX8KFvn"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print('Test accuracy :', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvyPZGh6KFvn"
      },
      "outputs": [],
      "source": [
        "#Retrieve a batch of images from the test set\n",
        "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
        "predictions = model.predict_on_batch(image_batch).flatten()\n",
        "\n",
        "# Apply a sigmoid since our model returns logits\n",
        "predictions = tf.nn.sigmoid(predictions)\n",
        "predictions = tf.where(predictions < 0.5, 0, 1)\n",
        "\n",
        "print('Predictions:\\n', predictions.numpy())\n",
        "print('Labels:\\n', label_batch)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "    plt.title(class_names[predictions[i]])\n",
        "    plt.axis(\"off\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Practice3-2_Transfer_Learning_dist.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}